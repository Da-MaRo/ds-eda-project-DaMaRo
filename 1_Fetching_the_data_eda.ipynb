{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL in Python - Connecting to and retrieving data from PostgreSQL\n",
    "\n",
    "Previously, you have learned how to connect to a SQL database by using a SQL client such as DBeaver. Apart from connecting to databases, DBeaver also allows you to run SQL queries against the database, create new tables and populate them with data as well as retrieving the data.\n",
    "\n",
    "Python also allows executing SQL queries and getting the result into a Python object, for example a Pandas data frame. Instead of exporting a .csv file from DBeaver you can directly get the data you need into Python and continue your work. In addition we can reduce the steps by connecting to the database from Python directly, eliminating the need for a separate SQL client.\n",
    "\n",
    "After you have the data in Python in the required shape you can export the data into a .csv file. This file is for your own reference, please avoid sending .csv files around - database is the point of reference when it comes to data. \n",
    "\n",
    "Having a copy of a .csv file (or another format) can speed up your analysis work. Imagine that the query takes 25 minutes to run. If you made some mistakes in your Python code you might need to go back to the original dataset. Instead of having to rerun the SQL query and having to wait you can read in the .csv file you have previously saved on your hard disk into Python and continue with your analysis work. \n",
    "\n",
    "**In this notebook you will see 2 ways to connect to SQL-Databases and export the data to a CSV file**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a connection to a PostgreSQL database with Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 python packages that are the \"go-to\" when it comes to connecting to SQL-Databases: `psycopg2` and `sqlalchemy` "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting via psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In order to create a connection to our PostgreSQL database we need the following information:\n",
    "\n",
    "- host = the address of the machine the database is hosted on\n",
    "- port = the virtual gate number through which communication will be allowed\n",
    "- database = the name of the database\n",
    "- user = the name of the user\n",
    "- password = the password of the user\n",
    "\n",
    "Because we don't want that the database information is published on github we put it into a `.env` file which is added into the `.gitignore`. \n",
    "In these kind of files you can store information that is not supposed to be published.\n",
    "With the `dotenv` package you can read the `.env` files and get the variables.\n",
    "(We will share the file with you on Slack!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "DATABASE = os.getenv('DATABASE')\n",
    "USER_DB = os.getenv('USER_DB')\n",
    "PASSWORD = os.getenv('PASSWORD')\n",
    "HOST = os.getenv('HOST')\n",
    "PORT = os.getenv('PORT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function from the psycopg2 package to create a connection is called `connect()`.\n",
    "`connect()` expects the parameters listed above as input in order to connect to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATABASE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Create connection object conn\u001b[39;00m\n\u001b[1;32m      2\u001b[0m conn \u001b[39m=\u001b[39m psycopg2\u001b[39m.\u001b[39mconnect(\n\u001b[0;32m----> 3\u001b[0m     database\u001b[39m=\u001b[39mDATABASE,\n\u001b[1;32m      4\u001b[0m     user\u001b[39m=\u001b[39mUSER_DB,\n\u001b[1;32m      5\u001b[0m     password\u001b[39m=\u001b[39mPASSWORD,\n\u001b[1;32m      6\u001b[0m     host\u001b[39m=\u001b[39mHOST,\n\u001b[1;32m      7\u001b[0m     port\u001b[39m=\u001b[39mPORT\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DATABASE' is not defined"
     ]
    }
   ],
   "source": [
    "# Create connection object conn\n",
    "conn = psycopg2.connect(\n",
    "    database=DATABASE,\n",
    "    user=USER_DB,\n",
    "    password=PASSWORD,\n",
    "    host=HOST,\n",
    "    port=PORT\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving data from the database with psycopg2\n",
    "\n",
    "Before we can use our connection to get data, we have to create a cursor. A cursor allows Python code to execute PostgreSQL commmands in a database session.\n",
    "A cursor has to be created with the `cursor()` method of our connection object conn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cur \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mcursor()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conn' is not defined"
     ]
    }
   ],
   "source": [
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run SQL-Queries with `cur.execute('QUERY')` and then run `cur.fetchall()` to get the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cur' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cur\u001b[39m.\u001b[39mexecute(\u001b[39m'\u001b[39m\u001b[39mSELECT * FROM eda.king_county_house_sales LIMIT 10\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m cur\u001b[39m.\u001b[39mfetchall()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cur' is not defined"
     ]
    }
   ],
   "source": [
    "cur.execute('SELECT * FROM eda.king_county_house_sales LIMIT 10')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `conn.close()` you can close the connection again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we want to work with the data. The easiest way is to import the data into pandas dataframes. We can use `pd.read_sql_query` or `pd.read_sql_table` or for convenience `pd.read_sql`.\n",
    "\n",
    "This function is a convenience wrapper around read_sql_table and read_sql_query (for backward compatibility). It will delegate to the specific function depending on the provided input. A SQL query will be routed to read_sql_query , while a database table name will be routed to read_sql_table . Note that the delegated function might have more specific notes about their functionality not listed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open connection again because we closed it\n",
    "conn = psycopg2.connect(\n",
    "    database=DATABASE,\n",
    "    user=USER_DB,\n",
    "    password=PASSWORD,\n",
    "    host=HOST,\n",
    "    port=PORT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data into a pandas dataframe\n",
    "query_string = \"SELECT * FROM eda.king_county_house_sales LIMIT 10\"\n",
    "df_psycopg = pd.read_sql(query_string, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_psycopg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the data to a csv-file\n",
    "df_psycopg.to_csv('data/eda.csv',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting and retrieving data via SQLAlchemy\n",
    "\n",
    "`sqlalchemy` works similarly. Here you have to create an engine with the database sting (a link that includes every information we entered in the conn object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "#read the database string from the .env\n",
    "load_dotenv()\n",
    "\n",
    "DB_STRING = os.getenv('DB_STRING')\n",
    "\n",
    "db = create_engine(DB_STRING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then you can import that engine with a query into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the data to a pandas dataframe\n",
    "query_string = \"SELECT * FROM eda.king_county_house_sales\"\n",
    "df_sqlalchemy = pd.read_sql(query_string, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sqlalchemy.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we don't want to run the queries over and over again we can export the data into a .csv file in order to use it in other notebooks as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the data to a csv-file\n",
    "df_sqlalchemy.to_csv('eda.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the data from a csv-file\n",
    "df_import = pd.read_csv('data/eda.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "86bfcc733a99316639cfae738bd2c12342c3c5e2c4e3f470908e9f9639795c12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
